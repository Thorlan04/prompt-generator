import streamlit as st
import os
from groq import Groq
from dotenv import load_dotenv
from datetime import datetime

# Configuration de la page
st.set_page_config(
    page_title="GÃ©nÃ©rateur de Prompts IA",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ©
st.markdown("""
    <style>
    .main {
        background-color: #f5f7fa;
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        flex-direction: column;
    }
    .chat-message.user {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    .chat-message.assistant {
        background-color: #f3e5f5;
        border-left: 4px solid #9c27b0;
    }
    .chat-icon {
        font-size: 1.5rem;
        margin-bottom: 0.5rem;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# Charger les variables d'environnement
load_dotenv()

# Initialiser la session
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'historique_conversation' not in st.session_state:
    st.session_state.historique_conversation = []
if 'conversation_terminee' not in st.session_state:
    st.session_state.conversation_terminee = False

# CORRECTION : Toujours recharger la clÃ© API
api_key = os.getenv("GROQ_API_KEY")
if api_key:
    # Nettoyer la clÃ© (enlever espaces, retours Ã  la ligne)
    api_key = api_key.strip()
    try:
        st.session_state.groq_client = Groq(api_key=api_key)
        st.session_state.api_key_valid = True
    except Exception as e:
        st.session_state.groq_client = None
        st.session_state.api_key_valid = False
        st.session_state.api_error = str(e)
else:
    st.session_state.groq_client = None
    st.session_state.api_key_valid = False

def afficher_message(role, content):
    """Affiche un message dans le chat"""
    icon = "ğŸ‘¤ Vous" if role == "user" else "ğŸ¤– Assistant"
    css_class = "user" if role == "user" else "assistant"
    
    st.markdown(f"""
        <div class="chat-message {css_class}">
            <div class="chat-icon">{icon}</div>
            <div>{content}</div>
        </div>
    """, unsafe_allow_html=True)

def poser_question_intelligente(historique, derniere_reponse=None):
    """Utilise Groq pour gÃ©nÃ©rer la prochaine question"""
    
    if not st.session_state.groq_client:
        return "âŒ Erreur : ClÃ© API Groq non configurÃ©e."
    
    if not historique:
        prompt_systeme = """Tu es un consultant expert qui aide les clients Ã  dÃ©finir leurs projets digitaux.

Ton rÃ´le :
- Poser UNE SEULE question prÃ©cise Ã  la fois
- Adapter tes questions aux rÃ©ponses prÃ©cÃ©dentes
- Proposer des exemples concrets si le client est vague
- Explorer : objectifs, public, budget, dÃ©lais, compÃ©tences, sÃ©curitÃ©

Aspects Ã  couvrir :
- Objectif et fonctionnalitÃ©s principales
- Public cible prÃ©cis
- Pays d'exploitation (rÃ©glementation)
- Secteur d'activitÃ©
- Budget et dÃ©lais
- Ã‰quipe disponible et compÃ©tences
- Besoins spÃ©ciaux (accessibilitÃ©, langues, etc.)
- DonnÃ©es sensibles Ã  protÃ©ger
- IntÃ©grations nÃ©cessaires (paiement, email, etc.)

AprÃ¨s 10+ Ã©changes approfondis, propose la validation.

RÃ©ponds UNIQUEMENT avec ta question, sans prÃ©ambule."""
        
        message = "Le client dÃ©marre. Pose-lui la premiÃ¨re question pour comprendre son projet."
    else:
        historique_texte = ""
        for i, echange in enumerate(historique, 1):
            historique_texte += f"\n{i}. Q: {echange['question']}\n   R: {echange['reponse']}\n"
        
        prompt_systeme = "Tu es un consultant expert. Continue Ã  approfondir le projet avec des questions pertinentes."
        message = f"""Historique :
{historique_texte}

DerniÃ¨re rÃ©ponse : {derniere_reponse}

Pose la prochaine question importante. Si tu as 10+ Ã©changes approfondis, propose : "Je pense avoir assez d'informations. Cliquez sur 'GÃ©nÃ©rer le Prompt' ou continuons."
"""
    
    try:
        response = st.session_state.groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": prompt_systeme},
                {"role": "user", "content": message}
            ],
            temperature=0.7,
            max_tokens=300
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"âŒ Erreur API : {str(e)}"

def generer_prompt_final(historique):
    """GÃ©nÃ¨re le prompt optimisÃ© final"""
    
    historique_texte = ""
    for i, echange in enumerate(historique, 1):
        historique_texte += f"\n{i}. Question : {echange['question']}\n   RÃ©ponse : {echange['reponse']}\n"
    
    prompt_generation = f"""Voici la conversation complÃ¨te avec le client :

{historique_texte}

GÃ©nÃ¨re un PROMPT OPTIMISÃ‰ ULTRA-COMPLET en Markdown avec TOUTES ces sections dÃ©taillÃ©es :

# ğŸ¯ PROMPT OPTIMISÃ‰ - [Titre du projet]

## A. DESCRIPTION DU PROJET
- Objectif principal dÃ©taillÃ© (2-3 phrases)
- FonctionnalitÃ©s principales (liste concrÃ¨te basÃ©e sur la conversation)
- Public cible (personas dÃ©taillÃ©s)
- Contexte mÃ©tier (pourquoi ce projet existe)

## B. CONTRAINTES ET RESSOURCES
- Budget : [montant exact ou fourchette mentionnÃ©e]
- DÃ©lais : [timeline mentionnÃ©e]
- Ã‰quipe disponible : [compÃ©tences mentionnÃ©es]
- Contraintes techniques : [infrastructure existante ou "from scratch"]

## C. SÃ‰CURITÃ‰ ET PROTECTION DES DONNÃ‰ES
### Mesures de sÃ©curitÃ© obligatoires :
- Chiffrement AES-256 pour donnÃ©es sensibles
- Authentification sÃ©curisÃ©e (OAuth 2.0 ou JWT)
- HTTPS/SSL obligatoire
- Sauvegardes automatiques quotidiennes
- Tests de pÃ©nÃ©tration avant production

### Protection des donnÃ©es personnelles :
- Minimisation : collecter uniquement le nÃ©cessaire
- DurÃ©e de conservation limitÃ©e et documentÃ©e
- Droits utilisateurs : accÃ¨s, rectification, suppression
- Chiffrement des donnÃ©es en base

### ConformitÃ© RGPD (si applicable) :
- Registre des traitements
- AIPD si traitement Ã  risque
- DPO si nÃ©cessaire
- Consentement explicite

## D. RÃ‰GLEMENTATION ET CONFORMITÃ‰
### RÃ©glementations applicables :
[Liste basÃ©e sur le pays et secteur mentionnÃ©s dans la conversation]

Exemples selon contexte :
- France gÃ©nÃ©ral : RGPD, CNIL
- E-commerce France : RGPD, DSP2, droit rÃ©tractation 14j, CGV obligatoires
- SantÃ© France : RGPD, HDS, secret mÃ©dical
- Finance : RGPD, DSP2, MIF II, ACPR

### Documents lÃ©gaux obligatoires :
- Mentions lÃ©gales
- Politique de confidentialitÃ©
- CGU (Conditions GÃ©nÃ©rales d'Utilisation)
- CGV si e-commerce
- Politique cookies

## E. Ã‰THIQUE ET IMPACT SOCIÃ‰TAL
### AccessibilitÃ© (WCAG 2.1 niveau AA) :
- Contrastes couleurs â‰¥ 4.5:1
- Navigation clavier complÃ¨te
- Textes alternatifs images
- Compatible lecteurs d'Ã©cran

### Ã‰quitÃ© :
- Pas de discrimination (origine, genre, Ã¢ge)
- Audit biais algorithmiques si IA
- Langage inclusif

### Environnement :
- Ã‰co-conception du code
- HÃ©bergeur "vert" si possible
- Optimisation images et mÃ©dias

## F. FAISABILITÃ‰ TECHNIQUE
### Stack recommandÃ©e (justifiÃ©e selon projet) :

**Frontend :**
- Framework : React / Vue.js / Svelte [choisir selon complexitÃ©]
- UI : Tailwind CSS / Material-UI
- State : Context API / Redux si complexe

**Backend :**
- Framework : Node.js + Express / Python + FastAPI / PHP + Laravel
- API : REST ou GraphQL
- Auth : JWT / OAuth 2.0

**Base de donnÃ©es :**
- Type : PostgreSQL (relationnel) / MongoDB (NoSQL)
- ORM : Prisma / TypeORM / Mongoose
- Cache : Redis si nÃ©cessaire

**HÃ©bergement recommandÃ© :**
[Adapter selon pays/budget mentionnÃ©]
- Frontend : Vercel / Netlify (gratuit)
- Backend : Railway / Render / OVH (selon RGPD)
- DB : Provider du backend ou sÃ©parÃ©
- CDN : Cloudflare (gratuit)

**APIs tierces recommandÃ©es :**
[Selon besoins mentionnÃ©s]
- Paiement : Stripe / PayPal / Mollie
- Email : SendGrid (100/jour gratuit) / Brevo
- SMS : Twilio
- Stockage fichiers : Cloudinary / AWS S3

### Architecture :
[SchÃ©ma textuel : Client â†’ CDN â†’ API â†’ DB]

### CompatibilitÃ© :
- Responsive (mobile-first)
- Navigateurs : Chrome, Firefox, Safari, Edge (2 derniÃ¨res versions)
- PWA si mobile important

## G. RISQUES ET CONTINGENCES
### Risques techniques :
1. Pannes serveur â†’ Monitoring 24/7, backup serveur
2. Bugs critiques â†’ Tests auto >80%, rollback
3. Performance â†’ Load testing, CDN, caching

### Risques sÃ©curitÃ© :
1. Cyberattaques â†’ Audit sÃ©cu, WAF, assurance cyber
2. Fuites donnÃ©es â†’ Chiffrement, accÃ¨s limitÃ©s, protocole RGPD

### Risques juridiques :
1. Non-conformitÃ© RGPD â†’ Audit juridique prÃ©-lancement

### Risques financiers :
1. DÃ©passement budget â†’ Tampon 20%, suivi hebdo
2. CoÃ»ts cachÃ©s â†’ Calcul prÃ©cis avec marge

## H. COMMUNICATION ET ADOPTION
### Lancement :
- Phase bÃªta : 10-50 testeurs
- Marketing : [canaux selon public cible]
- Incentives : [offres lancement]

### Support :
- Onboarding emails (sÃ©rie de 5)
- Tutoriels vidÃ©o
- FAQ complÃ¨te
- Support : chatbot + email

### KPIs adoption :
- Inscriptions / tÃ©lÃ©chargements
- RÃ©tention 7/30/90 jours
- NPS > 50

## I. INTERNATIONALISATION
### Langues :
[Selon conversation ou "FranÃ§ais uniquement au lancement"]

### ImplÃ©mentation :
- BibliothÃ¨que i18n appropriÃ©e
- Traduction professionnelle
- Adaptation culturelle (dates, devises, formats)

## J. DURABILITÃ‰ ET MAINTENANCE
### Documentation :
- README complet
- Documentation technique (Wiki)
- Guide contribution

### Tests :
- Tests unitaires
- Tests intÃ©gration
- Tests e2e
- Coverage > 80%

### CI/CD :
- GitHub Actions / GitLab CI
- DÃ©ploiement automatique
- Versioning sÃ©mantique

### Monitoring :
- Uptime (UptimeRobot)
- Erreurs (Sentry)
- Analytics (Plausible - RGPD)
- Performance (Lighthouse CI)

## K. INDICATEURS DE RÃ‰USSITE (KPIs)
### KPIs Business :
- Acquisition : [objectif X users/mois]
- Conversion : [taux objectif X%]
- Revenue : [CA objectif si applicable]
- ROI : [retour attendu sous X mois]

### KPIs Produit :
- Engagement : temps session > X min
- RÃ©tention : X% actifs aprÃ¨s 30j
- Satisfaction : NPS > 50

### KPIs Techniques :
- Performance : Lighthouse > 90
- Uptime : > 99.5%
- Bugs critiques : < 5/mois

### CoÃ»ts mensuels estimÃ©s :
- HÃ©bergement : X-Y â‚¬
- APIs : X-Y â‚¬
- Maintenance : X-Y â‚¬
- **TOTAL : X-Y â‚¬/mois**

## L. COLLABORATION ET ORGANISATION
### Ã‰quipe recommandÃ©e :
**MVP :**
- 1 Product Owner
- 1 Dev Full-Stack (ou 1 Front + 1 Back)
- 1 Designer UX/UI (freelance OK)

**Complet :**
[Adapter selon taille projet]

### MÃ©thodologie :
- Agile / Scrum
- Sprints 2 semaines
- Stand-ups quotidiens 15min

### Outils :
- Code : GitHub / GitLab
- Projet : Trello / Notion / Jira
- Communication : Slack / Discord
- Design : Figma
- Docs : Notion / Confluence

## âœ… CHECKLIST DE DÃ‰MARRAGE (30 jours)

### Semaine 1 : PrÃ©paration
- [ ] DÃ©finir MVP (fonctionnalitÃ©s essentielles)
- [ ] Valider budget et timeline
- [ ] Constituer Ã©quipe
- [ ] Ã‰tude concurrence rapide
- [ ] Audit RGPD initial
- [ ] Choisir stack technique

### Semaine 2 : Design & Architecture
- [ ] Wireframes
- [ ] Maquettes haute fidÃ©litÃ©
- [ ] Architecture technique validÃ©e
- [ ] Choix providers (hosting, APIs)
- [ ] Setup environnements (dev, staging, prod)

### Semaine 3-4 : DÃ©veloppement MVP
- [ ] Backend : API endpoints essentiels
- [ ] Frontend : Ã©crans principaux
- [ ] IntÃ©grations tierces
- [ ] Tests unitaires
- [ ] Documentation

### Semaine 5 : Tests & Corrections
- [ ] Tests utilisateurs bÃªta (10-20 personnes)
- [ ] Corrections bugs critiques
- [ ] Tests sÃ©curitÃ©
- [ ] Optimisation performances
- [ ] Validation RGPD finale

### Lancement :
- [ ] DÃ©ploiement production
- [ ] Monitoring activÃ©
- [ ] Communication lancement
- [ ] Support opÃ©rationnel

---

**ğŸš€ Ce prompt est COMPLET et ACTIONNABLE !**

GÃ©nÃ©rÃ© le {datetime.now().strftime('%d/%m/%Y Ã  %H:%M')}
Par GÃ©nÃ©rateur de Prompts IA - PropulsÃ© par Groq
"""

    try:
        response = st.session_state.groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "user", "content": prompt_generation}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        prompt_final = response.choices[0].message.content.strip()
        
        # Sauvegarder
        nom_fichier = f"prompt_optimise_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(nom_fichier, "w", encoding="utf-8") as f:
            f.write(prompt_final)
        
        return prompt_final, nom_fichier
    except Exception as e:
        return f"âŒ Erreur : {str(e)}", None

# ==================== INTERFACE PRINCIPALE ====================

# Header
st.title("ğŸš€ GÃ©nÃ©rateur de Prompts IA Optimaux")
st.markdown("**PropulsÃ© par Groq (Llama 3.3) - 100% Gratuit**")
st.divider()

# Sidebar
with st.sidebar:
    st.header("ğŸ“Š Tableau de bord")
    
    if st.session_state.groq_client and st.session_state.get('api_key_valid', False):
        st.success("âœ… API Groq connectÃ©e")
    else:
        st.error("âŒ API non configurÃ©e")
        if st.session_state.get('api_error'):
            st.warning(f"âš ï¸ Erreur : {st.session_state.api_error}")
        st.info("VÃ©rifiez GROQ_API_KEY dans .env")
    
    st.divider()
    
    # Statistiques
    nb_questions = len(st.session_state.historique_conversation)
    st.metric("ğŸ“ Questions posÃ©es", nb_questions)
    
    if nb_questions >= 10:
        st.success("âœ… Informations suffisantes")
    elif nb_questions >= 5:
        st.warning(f"â³ {10 - nb_questions} questions recommandÃ©es")
    else:
        st.info(f"ğŸ’¡ {10 - nb_questions} questions minimum")
    
    st.divider()
    
    # Commandes
    st.subheader("ğŸ’¡ Guide")
    st.markdown("""
    **Utilisation :**
    1. RÃ©pondez aux questions
    2. Soyez prÃ©cis (mais OK si vague)
    3. Minimum 5 questions
    4. Cliquez "GÃ©nÃ©rer" quand prÃªt
    """)
    
    st.divider()
    
    # Boutons d'action
    if st.button("ğŸ”„ Nouvelle conversation", use_container_width=True):
        st.session_state.messages = []
        st.session_state.historique_conversation = []
        st.session_state.conversation_terminee = False
        st.rerun()
    
    if st.session_state.historique_conversation and not st.session_state.conversation_terminee:
        if st.button("ğŸ“‹ Voir le rÃ©sumÃ©", use_container_width=True):
            st.session_state.show_resume = True
            st.rerun()

# Afficher le rÃ©sumÃ© si demandÃ©
if hasattr(st.session_state, 'show_resume') and st.session_state.show_resume:
    with st.expander("ğŸ“‹ RÃ©sumÃ© de vos rÃ©ponses", expanded=True):
        for i, echange in enumerate(st.session_state.historique_conversation, 1):
            st.markdown(f"**{i}. {echange['question']}**")
            st.markdown(f"â†’ {echange['reponse']}")
            st.divider()
        if st.button("Fermer"):
            st.session_state.show_resume = False
            st.rerun()

# Zone principale
if not st.session_state.groq_client:
    st.error("âš ï¸ Configuration API Groq requise")
    st.info("""
    **Pour dÃ©marrer :**
    1. CrÃ©ez un compte : https://console.groq.com/ (gratuit)
    2. CrÃ©ez une API Key
    3. Ajoutez dans `.env` : `GROQ_API_KEY=votre_clÃ©`
    4. Relancez l'application
    """)
else:
    # Afficher l'historique
    for message in st.session_state.messages:
        afficher_message(message["role"], message["content"])
    
    # Conversation non dÃ©marrÃ©e
    if not st.session_state.messages and not st.session_state.conversation_terminee:
        st.info("ğŸ‘‹ **Bienvenue !** Cliquez sur 'DÃ©marrer' pour commencer la conversation.")
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ¬ DÃ©marrer la conversation", use_container_width=True, type="primary"):
                with st.spinner("PrÃ©paration..."):
                    question_initiale = poser_question_intelligente([])
                st.session_state.messages.append({"role": "assistant", "content": question_initiale})
                st.rerun()
    
    # Conversation en cours
    elif not st.session_state.conversation_terminee:
        st.divider()
        
        # Zone de rÃ©ponse
        # GÃ©nÃ©rer une clÃ© unique basÃ©e sur le nombre de messages
        input_key = f"user_input_{len(st.session_state.messages)}"

        user_input = st.text_input(
            "Votre rÃ©ponse :",
            placeholder="Tapez votre rÃ©ponse ici...",
            key=input_key
)
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            if st.button("ğŸ“¤ Envoyer", use_container_width=True, type="primary"):
                if user_input:
                    # Ajouter rÃ©ponse utilisateur
                    st.session_state.messages.append({"role": "user", "content": user_input})
                    
                    # Enregistrer dans l'historique
                    derniere_question = st.session_state.messages[-2]["content"] if len(st.session_state.messages) >= 2 else "Question initiale"
                    st.session_state.historique_conversation.append({
                        "question": derniere_question,
                        "reponse": user_input
                    })
                    
                    # GÃ©nÃ©rer prochaine question
                    with st.spinner("ğŸ¤” L'IA rÃ©flÃ©chit..."):
                        prochaine_question = poser_question_intelligente(
                            st.session_state.historique_conversation,
                            user_input
                        )
                    st.session_state.messages.append({"role": "assistant", "content": prochaine_question})
                    
                    st.rerun()
                else:
                    st.warning("âš ï¸ Veuillez entrer une rÃ©ponse")
        
        with col2:
            if len(st.session_state.historique_conversation) >= 5:
                if st.button("âœ… GÃ©nÃ©rer le Prompt", use_container_width=True):
                    st.session_state.conversation_terminee = True
                    st.rerun()
            else:
                st.button("âœ… GÃ©nÃ©rer", disabled=True, use_container_width=True, 
                         help=f"RÃ©pondez Ã  au moins {5 - len(st.session_state.historique_conversation)} question(s) de plus")
    
    # GÃ©nÃ©ration du prompt
    if st.session_state.conversation_terminee:
        st.success("âœ… **Informations collectÃ©es !** GÃ©nÃ©ration du prompt en cours...")
        
        with st.spinner("âš™ï¸ GÃ©nÃ©ration (20-30 secondes)..."):
            prompt_final, nom_fichier = generer_prompt_final(st.session_state.historique_conversation)
        
        if nom_fichier:
            st.balloons()
            st.success(f"ğŸ‰ **Prompt gÃ©nÃ©rÃ© avec succÃ¨s !**")
            
            # Stats
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ“ Questions", len(st.session_state.historique_conversation))
            with col2:
                st.metric("ğŸ“„ Taille", f"{len(prompt_final)} car.")
            with col3:
                st.metric("ğŸ“‹ Sections", "12+")
            
            st.divider()
            
            # AperÃ§u
            with st.expander("ğŸ‘ï¸ AperÃ§u (600 premiers caractÃ¨res)", expanded=True):
                st.markdown(prompt_final[:600] + "...")
            
            # TÃ©lÃ©chargement
            st.download_button(
                label="ğŸ“¥ TÃ©lÃ©charger le prompt complet (.md)",
                data=prompt_final,
                file_name=nom_fichier,
                mime="text/markdown",
                use_container_width=True,
                type="primary"
            )
            
            # Prompt complet
            with st.expander("ğŸ“„ Voir le prompt complet"):
                st.markdown(prompt_final)
            
            st.divider()
            
            # Nouvelle conversation
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("ğŸ”„ CrÃ©er un nouveau prompt", use_container_width=True):
                    st.session_state.messages = []
                    st.session_state.historique_conversation = []
                    st.session_state.conversation_terminee = False
                    st.rerun()
        else:
            st.error(prompt_final)

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.9rem; padding: 1rem;'>
    <strong>GÃ©nÃ©rateur de Prompts IA</strong> â€¢ PropulsÃ© par <strong>Groq</strong> â€¢ 100% Gratuit<br>
    CrÃ©Ã© avec â¤ï¸ pour vous aider Ã  structurer vos projets digitaux
</div>
""", unsafe_allow_html=True)